
# ECS 189G, Spring 2023: 

# A Course on (Social) Fairness of Machine Learning Algorithms

lecture: 1:40-3 pm TR <br>
discussion: 4:10-5 pm R <br>
4 units <br>
N. Matloff ([my bio)](http://heather.cs.ucdavis.edu/matloff.html)

## Overview

Are machine learning (ML) algorithms biased against minorities and women?

* A 2016
[Pro Publica article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) investigated COMPAS, an ML algorithm designed to predict recidivism by
those convicted of crimes.  The article found the tool to be racially biased,
of major concern since it was being used by judges as an aid in
sentencing convicts. 

* Actually, these and other biases are commonplace. What can be done to
detect and remedy bias?

## Prerequisites

* Students *both* from within *and* from outside computer science are
encouraged to enroll.

* Since students will work in groups, strengths of some group members
  may complement those of others in the group.

* However, everyone is assume to have some minimal background in:

    - Coding:  Loops, functions, if-else.  We will use R; see [my quick
      tutorial](https://github.com/matloff/fasteR).
    
    - Statistics:  Bayes Rule for probabilities; confidence intervals.  Some
      exposure to linear regression models would be helpful.

* `Common sense` understanding proportions, e.g. difference between
  proportion of x among y vs. proportion of y among x.  E.g. many
  [serious conceptual errors](https://twitter.com/jsm2334/status/1462573183970824201) have been made regarding Covid-19.
